{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e02b66c-a2c4-4517-9501-c267609dc670",
   "metadata": {},
   "source": [
    "# I Trained an AI Model to Generate Donald Trump Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16351139-456e-44b4-8fa1-fd212aada19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "from os.path import exists\n",
    "\n",
    "# Data Parameters\n",
    "tweet_length = 280\n",
    "train_frac = 0.667\n",
    "pre_shuffle = 1000\n",
    "batch = 100\n",
    "\n",
    "# Training parameters\n",
    "train = False\n",
    "shuffle = True\n",
    "epochs = 20\n",
    "\n",
    "# Model parameters\n",
    "embedding_units = 256\n",
    "lstm_units = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e95731d-d386-47d3-903e-9d021c476542",
   "metadata": {},
   "source": [
    "Before we train, let's check the devices available on our system. If we don't see any GPU's or other hardware accelerators, our training will run on the CPU (which could be a problem for home machines that cannot throttle the number of available CPU cores for training and the training will exhaust the CPU's resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d66a503-a37d-4f04-b0c2-cf6be13e888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogicalDevice(name='/device:CPU:0', device_type='CPU')\n",
      "LogicalDevice(name='/device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "print(*tf.config.list_logical_devices(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16328a5-0587-4b47-93b0-983c04305adf",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "With AI, data processing is half the battle. So we'll spend a lot of time exploring and processing the data before we build our AI model. I want these to run mainly on the CPU, so we have access to our main memory and frankly it's faster for this step (on my machine). We're only concerned with the text, since we're just trying to make funny tweets, so we're . gonna filter out just links. Also filter for retweets, since we need the raw chaotic energy from the man's gorgeous mouth itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71558702-dc8f-4fe5-b2de-b544c7f0f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train or not exists('models/_support/ai-donald-trump-vectorizer.json'):\n",
    "    df = pd.read_csv('data/dtweets.csv', encoding='utf-8')\n",
    "    df = df.loc[~((df['text'].str.startswith('RT @')) | (df['text'].str.startswith('\"RT @')))]\n",
    "    df = df.loc[~(df['text'].str.match(r'https?\\:\\/\\/t.co/[a-zA-Z0-9]+'))]\n",
    "    tweets = df['text']\n",
    "    tweets = tweets.sample(frac=1)\n",
    "    tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d37ae-6685-443e-a9c2-d3712cc37d0e",
   "metadata": {},
   "source": [
    "Next, create and train character encoder and decoder. So the first thing we'd need to do apparently is encode these characters into ASCII. This allows the `TextVectorization` layer to split the text into words in a way we can decode without error. Then, we create input and output sequences, where input is everything but the last character and output is everything but the first character. We also pad the characters so that they're all the same length (easier to work with, maybe). Finally, create dataset, we also split into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c4459a-d318-488b-9ecf-c4b7e5592684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 95\n"
     ]
    }
   ],
   "source": [
    "if train or not exists('models/_support/ai-donald-trump-vectorizer.json'):\n",
    "    with tf.device('/device:CPU:0'):\n",
    "        # Encoder\n",
    "        encoded_tweets = tweets.str.encode('ascii', errors='ignore')\n",
    "        word2vec = tf.keras.layers.TextVectorization(split='character', standardize=None)\n",
    "        word2vec.adapt(encoded_tweets)\n",
    "        vocab_size = word2vec.vocabulary_size()\n",
    "        print('Save vectorizer...')\n",
    "        with open('models/_support/ai-donald-trump-vectorizer.json', 'w+') as f:\n",
    "            json.dump(word2vec.get_vocabulary(), f)\n",
    "\n",
    "        # Encode and split tweets\n",
    "        vectorized_tweets = word2vec(encoded_tweets)\n",
    "        input_tweet_seqs = vectorized_tweets[:,:-1]\n",
    "        output_tweet_seqs = vectorized_tweets[:,1:]\n",
    "\n",
    "        # Create dataset and split into training and testing\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            input_tweet_seqs, \n",
    "            output_tweet_seqs))\n",
    "        dataset = dataset.shuffle(pre_shuffle)\n",
    "        dataset = dataset.batch(batch)\n",
    "        train_num = int(len(dataset)*train_frac)\n",
    "        train_dataset = dataset.take(train_num)\n",
    "        test_dataset = dataset.skip(train_num)\n",
    "else:\n",
    "    with open('models/_support/ai-donald-trump-vectorizer.json', 'r') as f:\n",
    "        word2vec = tf.keras.layers.TextVectorization(split='character', \n",
    "                                                     standardize=None, \n",
    "                                                     vocabulary=json.load(f))\n",
    "        vocab_size = word2vec.vocabulary_size()\n",
    "\n",
    "decodeidx = lambda sample: ''.join(word2vec.get_vocabulary()[idx] for idx in sample)\n",
    "print('Vocab Size:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751c0ae-b82f-4565-a33d-30495653e5c5",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now for the fun part, we create the model and train it using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d5a0c8-65d5-453e-9254-7332f9340f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 256)         24320     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 1024)        5246976   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 95)          97375     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,368,671\n",
      "Trainable params: 5,368,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# TODO: Create model using keras object oriented\n",
    "#       framework and be able to pass state to \n",
    "#       LSTM if needed\n",
    "\n",
    "# Load or create model\n",
    "if train:\n",
    "    print('Creating model...')\n",
    "    model = tf.keras.Sequential([\n",
    "        Embedding(vocab_size, embedding_units),\n",
    "        LSTM(lstm_units, return_sequences=True),\n",
    "        Dense(vocab_size, activation='linear')\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "else:\n",
    "    print('Loading model...')\n",
    "    model = tf.keras.models.load_model('models/ai-donald-trump')\n",
    "    \n",
    "# Print summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec925c09-7664-4fee-9b43-5f8756f2a803",
   "metadata": {},
   "source": [
    "Train the model with the data. Fingers crossed this goes well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7fa690f-5ac4-471b-8e30-f3fd77d5d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    model.fit(train_dataset,\n",
    "              validation_data=test_dataset,\n",
    "              epochs=epochs,\n",
    "              shuffle=shuffle,\n",
    "              callbacks=[\n",
    "                  tf.keras.callbacks.EarlyStopping(patience=5)\n",
    "              ])\n",
    "    model.save('models/ai-donald-trump')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5849e18-290e-45ec-8d9d-84e16458ffd7",
   "metadata": {},
   "source": [
    "Generate a sentence using our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "802605bc-389d-496c-8127-c891ba9f99f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1da06b252bc400898c7eee0fe1f4eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Textarea(value='Mitch McConnell', description='Prompt:', placeholder='Type a prompt'), Button(bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Implement OneStepGenerator model\n",
    "\n",
    "# Interactive widgets\n",
    "prompt_widget = widgets.Textarea(value='Mitch McConnell',\n",
    "                                 placeholder='Type a prompt',\n",
    "                                 description='Prompt:')\n",
    "generate_widget = widgets.Button(description='Generate',\n",
    "                                 button_style='info')\n",
    "output_widget = widgets.Output()\n",
    "app_widget = widgets.VBox([\n",
    "    prompt_widget, \n",
    "    generate_widget, \n",
    "    output_widget\n",
    "])\n",
    "\n",
    "\n",
    "# Prediction routine\n",
    "@output_widget.capture(clear_output=True)\n",
    "def run_prediction(event):\n",
    "    \"\"\"\n",
    "    Generate a sentence with prompt \n",
    "    provided by widget\n",
    "    \n",
    "    :param event: button click event\n",
    "    \"\"\"\n",
    "    # Get prompt value\n",
    "    prompt = prompt_widget.value\n",
    "    if prompt == '':\n",
    "        raise Exception('Please enter a prompt!')\n",
    "    \n",
    "    # Encode prompt\n",
    "    prompt_encoded = word2vec([prompt])\n",
    "    \n",
    "    # Generate tweet chars starting from prompt\n",
    "    prediction_indeces = prompt_encoded\n",
    "    for i in tqdm(range(280 - len(prompt)), desc=\"Generating\"):\n",
    "        prediction_labels = model.predict(prediction_indeces, verbose=0)\n",
    "        next_prediction_indeces = tf.random.categorical(prediction_labels[0], num_samples=1)\n",
    "        next_prediction_indeces = tf.reshape(next_prediction_indeces, [1, -1])\n",
    "        prediction_indeces = tf.concat([prediction_indeces, [[next_prediction_indeces[0,-1]]]], axis=1)\n",
    "    prediction_indeces = tf.squeeze(prediction_indeces, axis=0).numpy()\n",
    "    \n",
    "    # Decode and print prediction\n",
    "    prediction = decodeidx(prediction_indeces)\n",
    "    print('Prediction:', prediction)\n",
    "\n",
    "\n",
    "# Hook up app and display\n",
    "generate_widget.on_click(run_prediction)\n",
    "app_widget"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
